{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "R2Zm8HGgT2xI",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip -q install openai arxiv PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "from enum import Enum\n",
        "from typing import Union\n",
        "\n",
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "import arxiv\n",
        "import fitz\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_KEY')\n"
      ],
      "metadata": {
        "id": "xEhpYTvbUdXZ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def download_single_paper(query: str):\n",
        "    search = arxiv.Search(\n",
        "        query=query,\n",
        "        max_results=1,  # We only want to retrieve one paper\n",
        "        sort_by=arxiv.SortCriterion.Relevance\n",
        "    )\n",
        "    result = next(search.results(), None)\n",
        "\n",
        "    if result:\n",
        "        dir_path = os.path.join('./data', query.replace(' ', ''))\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "        file_path = result.download_pdf(dirpath=dir_path)\n",
        "        print(f\"Downloaded paper: {result.title}\")\n",
        "        return file_path\n",
        "    else:\n",
        "        print(\"No papers found for this query.\")\n",
        "        return None, None, None, None, None\n"
      ],
      "metadata": {
        "id": "hWhRBjKbpsPD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path= download_single_paper('LLM')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CsGEVDuqp3Au",
        "outputId": "4aae259d-f129-42cb-c951-1fd50ebb2a3a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-07f1117b8afb>:7: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  result = next(search.results(), None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded paper: Large Language Models as Software Components: A Taxonomy for LLM-Integrated Applications\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def parse_pdf(file_path: str) -> str:\n",
        "    doc = fitz.open(file_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "article = parse_pdf(file_path)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HR27vCDmqCuz"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "\n",
        "class SectionType(BaseModel):\n",
        "    \"\"\"\n",
        "    Enumeration of section types in an academic paper.\n",
        "\n",
        "    This model represents the summary of different sections that can be found in an academic paper.\n",
        "    \"\"\"\n",
        "    abstract : str\n",
        "    introduction : str\n",
        "    methodology : str\n",
        "    results : str\n",
        "    conclusion : str\n",
        "\n",
        "class PaperType(str, Enum):\n",
        "    \"\"\"\n",
        "    Enumeration of academic paper types.\n",
        "\n",
        "    This enum represents different categories of academic papers.\n",
        "    \"\"\"\n",
        "    research_article = \"research_article\"\n",
        "    review_article = \"review_article\"\n",
        "    conference_paper = \"conference_paper\"\n",
        "    thesis = \"thesis\"\n",
        "    dissertation = \"dissertation\"\n",
        "\n",
        "class Author(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents an author of an academic paper.\n",
        "\n",
        "    This model captures basic information about an author, including their name\n",
        "    and affiliation.\n",
        "    \"\"\"\n",
        "    name: str\n",
        "    affiliation: str\n",
        "\n",
        "class PaperMetadata(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents metadata of an academic paper.\n",
        "\n",
        "    This model captures basic metadata about an academic paper, including its title,\n",
        "    authors, publication date, and journal.\n",
        "    \"\"\"\n",
        "    title: str\n",
        "    authors: List[Author]\n",
        "    publication_date: str\n",
        "    journal: str\n",
        "    paper_type: PaperType\n",
        "\n",
        "class AcademicPaperResponse(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents the structured response for an academic paper analysis.\n",
        "\n",
        "    This model aggregates information about the paper's metadata and its section's summary.\n",
        "    \"\"\"\n",
        "    metadata: PaperMetadata\n",
        "    sections: SectionType\n"
      ],
      "metadata": {
        "id": "AXjVHf_An_zk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()\n",
        "\n",
        "completion = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that scans for \\\n",
        "       different sections of a research paper.\"},\n",
        "        {\"role\": \"user\", \"content\": article},\n",
        "    ],\n",
        "    response_format=AcademicPaperResponse,\n",
        ")\n",
        "\n",
        "message = completion.choices[0].message\n",
        "\n"
      ],
      "metadata": {
        "id": "vKsHtKZvPoyQ",
        "collapsed": true
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message.parsed.metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiwZuYYPuV1U",
        "outputId": "28f840c2-f586-4bfd-987c-66719f06834d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PaperMetadata(title='Large Language Models as Software Components: A Taxonomy for LLM-Integrated Applications', authors=[Author(name='Irene Weber', affiliation='Kempten University of Applied Sciences, Germany')], publication_date='13 Jun 2024', journal='arXiv', paper_type=<PaperType.research_article: 'research_article'>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in message.parsed.sections:\n",
        "    print(i[0] + ': \\n')\n",
        "    print(i[1] + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k9ltxqbq2SF",
        "outputId": "4a7f93f0-8f90-4271-f71f-ae0aa7cb503b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abstract: \n",
            "\n",
            "Large Language Models (LLMs) have become widely adopted as tools for software engineering. This study presents a taxonomy to describe LLM-integrated applications, identifying essential dimensions for characterizing these systems. By analyzing recent applications, the taxonomy reveals the diverse integration methods and suggests a framework using feature vectors for visualization, aiming to advance the nascent field of LLM-integrated application engineering.\n",
            "\n",
            "introduction: \n",
            "\n",
            "Large Language Models (LLMs) have significantly impacted fields such as medicine, law, marketing, and education, due to their proficiency in tasks like text understanding and code writing. The study explores LLMs as components in software systems, contrasting with traditional views of LLMs as software development tools, offering a taxonomy to frame LLM-integrated application engineering as an emerging research area.\n",
            "\n",
            "methodology: \n",
            "\n",
            "The taxonomy was developed using a Design Science Research approach, applying established methods for taxonomy design. A sample of industrial and technical LLM-integrated applications was analyzed through an empirical-to-conceptual process, identifying dimensions and characteristics over several development cycles, followed by an evaluation phase to validate the taxonomy.\n",
            "\n",
            "results: \n",
            "\n",
            "The study defined a taxonomy comprising initiation, function, prompt, skills, and output-related dimensions to categorize LLM components. These dimensions are applied to various LLM-integrated applications, demonstrating how they leverage LLM capabilities to perform specific tasks and illustrating diverse architectural setups.\n",
            "\n",
            "conclusion: \n",
            "\n",
            "The taxonomy provides a structured framework for analyzing LLM-integrated applications, contributing to theory building in the field by establishing common terminology and highlighting design options. This study suggests that understanding LLM components is crucial for grasping an application's architecture, offering insights for future research and development within this domain.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bgOEZxpbuCVY"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}